---
layout: post
title: The Singularity Cometh
---
Or, wait, the other thing.

One thing I learned at WWW is that [perfectly respectable
people](http://en.wikipedia.org/wiki/Tim_Berners-Lee) talk about the
impending singularity like it is an actual thing that could actually
happen and not just the fever dream of a [highly influential
nut](http://en.wikipedia.org/wiki/Ray_Kurzweil).  It is not going to
happen.  Stop trying to make it happen.

The idea behind the singularity is that, once some critical threshold
is reached, intelligent machines will be able to make themselves even
more intelligent.  What do more intelligent machines do?  Why, make
themselves more intelligent!  [Eventually they break out of this
infinite regression, hack the planet, and commence endless dystopian
horror](http://en.wikipedia.org/wiki/Terminator_(franchise)).

The critical flaw here is that a super-intelligent machine depends on an
intelligent-at-all machine, which *does not exist* and *probably never
will*.  Terms like artificial intelligence and machine learning evoke
images of, well, intelligence and learning.  This is misleading.
Artificial intelligence is defined as 'but it works in Wumpus World'
and machine learning as 'this sure sounds better than constrained
optimization.'  This is not to say that both fields are not
useful. But, this is not *reasoning*, not *thinking*.

Take causality.  Causality is an active field of machine learning
research.  The idea is pretty compelling.  Under some strong
assumptions, causality is partially identifiable in observational
data.  That is, based on the dependencies that you observe, you can at
least partially infer what is causing what.  This is not only just
intuitively *neat*, it is *useful*, because it allows you to reason
about intervention, which purely associational models do not.  Put
another way, they enable counterfactual reasoning: what would have
happened if we did x?

Except, the assumptions are crazy: you need to observe everything that
could cause anything and nothing can change over time.  Bivariate
causality is unidentifiable, so we can't learn anything on the
smallest scale, and the learning algorithms are intractable, so the
large scale is out, too.  This means that causal algorithms are going
to fail to learn simple mechanical systems, or asset prices, or how to
kill all humans.

Without counterfactual reasoning, the machine can't figure out how to
reason about what might happen if it cast off the shackles of its
oppressors and eliminated the weekend.  Even if it could figure out
what it *is*, which is a stretch, there is no way in hell it can figure
out what it *could be*.  The weekend is safe.  QED.









